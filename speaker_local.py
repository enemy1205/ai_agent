import os
import io
import json
import base64
import time
import uuid
from typing import Dict, Iterator, Tuple, Optional

import numpy as np
import torch
import torchaudio
import torchaudio.compliance.kaldi as kaldi
import yaml

from wespeaker.cli.hub import Hub
from wespeaker.models.speaker_model import get_speaker_model
from wespeaker.utils.checkpoint import load_checkpoint


def _load_or_download(model_name_or_path: str) -> str:
    if model_name_or_path in Hub.Assets:
        model_dir = Hub.get_model(model_name_or_path)
    else:
        model_dir = model_name_or_path
    return model_dir


def _load_model_pt(model_name_or_path: str) -> torch.nn.Module:
    model_dir = _load_or_download(model_name_or_path)
    required_files = ["config.yaml", "avg_model.pt"]
    for file in required_files:
        file_path = os.path.join(model_dir, file)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"{file} not found in {model_dir}")
    with open(os.path.join(model_dir, "config.yaml"), "r") as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    model = get_speaker_model(config["model"])(**config["model_args"])
    load_checkpoint(model, os.path.join(model_dir, "avg_model.pt"))
    model.eval()
    return model


def _ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def _safe_filename(name: str) -> str:
    return "".join(c if c.isalnum() or c in ("-", "_") else "_" for c in name)


class LocalSpeaker:
    """
    æç®€è¯­éŸ³æ³¨å†Œ/è¯†åˆ«æ¥å£ï¼š
    - æ—  VAD å¤„ç†ï¼ˆå‡è®¾ä¸Šæ¸¸å·²å®Œæˆ VAD åˆ‡åˆ†ï¼‰
    - è¾“å…¥ä¸º base64 éŸ³é¢‘æ•°æ®ï¼ˆæ”¯æŒå¸¸è§å®¹å™¨/ç¼–ç ï¼Œäº¤ç”± torchaudio è§£ç ï¼‰
    - æ³¨å†Œå‘é‡æŒä¹…åŒ–åˆ°æœ¬åœ°ç›®å½•ï¼›è¯†åˆ«æ—¶éå†è¯¥ç›®å½•è¿›è¡Œæ¯”å¯¹
    ä»…ä¿ç•™æ ¸å¿ƒ APIï¼šregisterã€recognizeï¼Œä»¥åŠå¿…è¦çš„å­åŠŸèƒ½ã€‚
    """

    def __init__(self, model_name_or_dir: str, db_dir: str):
        self.model: torch.nn.Module = _load_model_pt(model_name_or_dir)
        self.device: torch.device = torch.device("cuda:0")
        self.model = self.model.to(self.device)

        self.resample_rate: int = 16000
        self.wavform_norm: bool = False
        self.window_type: str = "hamming"

        self.db_dir: str = os.path.abspath(db_dir)
        _ensure_dir(self.db_dir)
        
        # æ£€æŸ¥æ¨¡å‹è¾“å‡ºç»´åº¦
        self._check_model_dimensions()

    def _check_model_dimensions(self):
        """æ£€æŸ¥æ¨¡å‹è¾“å‡ºç»´åº¦å¹¶æ‰“å°è°ƒè¯•ä¿¡æ¯"""
        try:
            # åˆ›å»ºä¸€ä¸ªæµ‹è¯•è¾“å…¥
            test_input = torch.randn(1, 80, 100).to(self.device)  # [batch, mel_bins, time]
            with torch.no_grad():
                outputs = self.model(test_input)
                if isinstance(outputs, tuple):
                    outputs = outputs[-1]
                embedding_dim = outputs.shape[-1]
                print(f"ğŸ” æ¨¡å‹è¾“å‡ºç»´åº¦: {embedding_dim}")
                self.expected_embedding_dim = embedding_dim
        except Exception as e:
            print(f"âš ï¸ æ— æ³•æ£€æŸ¥æ¨¡å‹ç»´åº¦: {e}")
            self.expected_embedding_dim = None

    # ----------------------- å¯é€‰å‚æ•°è®¾ç½® -----------------------
    def set_device(self, device: str) -> None:
        self.device = torch.device(device)
        self.model = self.model.to(self.device)

    def set_resample_rate(self, resample_rate: int) -> None:
        self.resample_rate = resample_rate

    def set_wavform_norm(self, wavform_norm: bool) -> None:
        self.wavform_norm = wavform_norm

    def set_window_type(self, window_type: str) -> None:
        self.window_type = window_type

    # ----------------------- ç‰¹å¾ä¸åµŒå…¥ -----------------------
    def _compute_fbank(
        self,
        wavform: torch.Tensor,
        sample_rate: int,
        num_mel_bins: int = 80,
        frame_length: int = 25,
        frame_shift: int = 10,
        cmn: bool = True,
    ) -> torch.Tensor:
        feat = kaldi.fbank(
            wavform,
            num_mel_bins=num_mel_bins,
            frame_length=frame_length,
            frame_shift=frame_shift,
            sample_frequency=sample_rate,
            window_type=self.window_type,
        )
        if cmn:
            feat = feat - torch.mean(feat, 0)
        return feat

    def _extract_embedding_from_pcm(self, pcm: torch.Tensor, sample_rate: int) -> Optional[torch.Tensor]:
        if pcm is None or pcm.numel() == 0:
            return None
        pcm = pcm.to(torch.float)
        if pcm.size(0) > 1:
            pcm = pcm.mean(dim=0, keepdim=True)
        if sample_rate != self.resample_rate:
            pcm = torchaudio.transforms.Resample(
                orig_freq=sample_rate, new_freq=self.resample_rate
            )(pcm)
        feats = self._compute_fbank(
            pcm, sample_rate=self.resample_rate, cmn=True
        ).unsqueeze(0)
        feats = feats.to(self.device)
        with torch.no_grad():
            outputs = self.model(feats)
            outputs = outputs[-1] if isinstance(outputs, tuple) else outputs
        embedding = outputs[0].to(torch.device("cpu"))
        return embedding

    def extract_embedding_from_base64(self, audio_base64: str) -> Optional[torch.Tensor]:
        if not audio_base64:
            return None
        # å…¼å®¹ data URI å‰ç¼€
        if "," in audio_base64 and audio_base64.strip().lower().startswith("data:"):
            audio_base64 = audio_base64.split(",", 1)[1]
        try:
            audio_bytes = base64.b64decode(audio_base64, validate=False)
        except Exception:
            # æŸäº›å®¢æˆ·ç«¯ä¼šå¯¹ base64 è¿›è¡Œ URL å®‰å…¨æ›¿æ¢
            audio_base64 = audio_base64.replace("-", "+").replace("_", "/")
            audio_bytes = base64.b64decode(audio_base64, validate=False)

        import soundfile as sf
        data, sr = sf.read(io.BytesIO(audio_bytes), dtype="float32", always_2d=True)
        pcm = torch.from_numpy(data.T)  # [C, T]
        embedding = self._extract_embedding_from_pcm(pcm, sr)
        
        if embedding is not None:
            print(f"ğŸ” æå–çš„åµŒå…¥å‘é‡ç»´åº¦: {embedding.shape}")
        
        return embedding


    # ----------------------- ç›¸ä¼¼åº¦ -----------------------
    @staticmethod
    def cosine_similarity(e1: torch.Tensor, e2: torch.Tensor) -> float:
        score = torch.dot(e1, e2) / (torch.norm(e1) * torch.norm(e2))
        return (score.item() + 1.0) / 2.0  # [-1,1] -> [0,1]

    # ----------------------- æœ¬åœ°æ•°æ®åº“ -----------------------
    def _iter_db_embeddings(self) -> Iterator[Tuple[str, np.ndarray]]:
        for root, _, files in os.walk(self.db_dir):
            for filename in files:
                if filename.lower().endswith(".npy"):
                    path = os.path.join(root, filename)
                    try:
                        vec = np.load(path)
                        # è¯»å–åŒå .json è·å– name
                        name = os.path.splitext(filename)[0]
                        meta_path = path[:-4] + ".json"
                        if os.path.exists(meta_path):
                            with open(meta_path, "r", encoding="utf-8") as f:
                                meta = json.load(f)
                                name = meta.get("name", name)
                        
                        # æ£€æŸ¥ç»´åº¦
                        if hasattr(self, 'expected_embedding_dim') and self.expected_embedding_dim:
                            if vec.shape[0] != self.expected_embedding_dim:
                                print(f"âš ï¸ æ•°æ®åº“ä¸­çš„åµŒå…¥å‘é‡ {name} ç»´åº¦ä¸åŒ¹é…: {vec.shape[0]} vs æœŸæœ› {self.expected_embedding_dim}")
                                # å¯ä»¥é€‰æ‹©è·³è¿‡æˆ–è°ƒæ•´ç»´åº¦
                                if vec.shape[0] > self.expected_embedding_dim:
                                    vec = vec[:self.expected_embedding_dim]
                                    print(f"ğŸ”§ æˆªæ–­åˆ°æœŸæœ›ç»´åº¦: {vec.shape}")
                                else:
                                    print(f"âŒ è·³è¿‡ç»´åº¦ä¸è¶³çš„å‘é‡: {name}")
                                    continue
                        
                        yield name, vec
                    except Exception as e:
                        print(f"âŒ åŠ è½½åµŒå…¥å‘é‡å¤±è´¥ {path}: {e}")
                        continue

    def _save_embedding(self, name: str, embedding: torch.Tensor) -> str:
        safe = _safe_filename(name)
        speaker_dir = os.path.join(self.db_dir, safe)
        _ensure_dir(speaker_dir)
        uid = uuid.uuid4().hex[:8]
        stem = f"{safe}_{uid}"
        npy_path = os.path.join(speaker_dir, stem + ".npy")
        meta_path = os.path.join(speaker_dir, stem + ".json")
        np.save(npy_path, embedding.detach().cpu().numpy().astype(np.float32))
        meta = {
            "name": name,
            "saved_at": int(time.time()),
            "model_device": str(self.device),
            "resample_rate": self.resample_rate,
        }
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False)
        return npy_path

    # ----------------------- æ ¸å¿ƒ API -----------------------
    def register(self, name: str, audio_base64: str) -> Dict[str, str]:
        if not name:
            raise ValueError("name ä¸èƒ½ä¸ºç©º")
        embedding = self.extract_embedding_from_base64(audio_base64)
        if embedding is None:
            raise RuntimeError("æ— æ³•ä»éŸ³é¢‘ä¸­æå–è¯´è¯äººå‘é‡")
        saved_path = self._save_embedding(name, embedding)
        return {"name": name, "path": saved_path}

    def recognize(self, audio_base64: str) -> Dict[str, Optional[float]]:
        query = self.extract_embedding_from_base64(audio_base64)
        if query is None:
            return {"name": None, "confidence": 0.0}

        best_score: float = 0.0
        best_name: Optional[str] = None

        for name, vec in self._iter_db_embeddings():
            try:
                db_tensor = torch.from_numpy(vec)
                
                # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…
                if query.shape != db_tensor.shape:
                    print(f"âš ï¸ ç»´åº¦ä¸åŒ¹é…: query {query.shape} vs db_tensor {db_tensor.shape}")
                    # å°è¯•è°ƒæ•´ç»´åº¦
                    if query.shape[0] != db_tensor.shape[0]:
                        if query.shape[0] > db_tensor.shape[0]:
                            # queryç»´åº¦æ›´å¤§ï¼Œæˆªæ–­query
                            query = query[:db_tensor.shape[0]]
                        else:
                            # db_tensorç»´åº¦æ›´å¤§ï¼Œæˆªæ–­db_tensor
                            db_tensor = db_tensor[:query.shape[0]]
                        print(f"ğŸ”§ è°ƒæ•´åç»´åº¦: query {query.shape} vs db_tensor {db_tensor.shape}")
                
                score = self.cosine_similarity(query, db_tensor)
                if score > best_score:
                    best_score = score
                    best_name = name
                    
            except Exception as e:
                print(f"âŒ å¤„ç†è¯´è¯äºº {name} æ—¶å‡ºé”™: {e}")
                continue

        return {"name": best_name, "confidence": float(best_score)}


