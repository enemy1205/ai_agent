#!/usr/bin/env python3
"""
HTTP Agent Server
å°†äº¤äº’å¼AI agentæ”¹é€ ä¸ºHTTPæœåŠ¡ç«¯ï¼Œæ”¯æŒå®¢æˆ·ç«¯é€šè¿‡HTTPè¯·æ±‚è°ƒç”¨æœ¬åœ°è‡ªå»ºå·¥å…·
"""

import os
import argparse
from pathlib import Path
from typing import Any
from flask import Flask, request, jsonify
from flask_cors import CORS
from langchain.agents import initialize_agent, AgentType
from langchain_openai import OpenAI
from langchain_core.callbacks import BaseCallbackHandler
import logging
import json

# å¯¼å…¥æœºå™¨äººæ§åˆ¶å·¥å…·
from robot_tools import (
    get_all_tools, get_tool_names, get_tools_info
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Flaskåº”ç”¨é…ç½®
app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# å…¨å±€å˜é‡å­˜å‚¨agentå®ä¾‹å’Œé…ç½®
agent = None
llm_endpoint = "http://localhost:8000/v1"

class ToolResultCallbackHandler(BaseCallbackHandler):
    """è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºæ•è·å·¥å…·æ‰§è¡Œç»“æœ"""
    
    def __init__(self):
        super().__init__()
        self.tool_outputs = []  # å­˜å‚¨æ‰€æœ‰å·¥å…·çš„è¿”å›å€¼
        self.tool_calls = []    # å­˜å‚¨å·¥å…·è°ƒç”¨ä¿¡æ¯
    
    def on_tool_start(self, serialized: dict, input_str: str, **kwargs) -> None:
        """å·¥å…·å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨"""
        tool_name = serialized.get('name', 'unknown')
        try:
            safe_input = (
                input_str if isinstance(input_str, str)
                else json.dumps(input_str, ensure_ascii=False)
            )
        except Exception:
            safe_input = str(input_str)
        logger.info(f"ğŸ› ï¸ å·¥å…· {tool_name} å¼€å§‹æ‰§è¡Œï¼Œè¾“å…¥: {safe_input}")
        self.tool_calls.append({
            'name': tool_name,
            'input': safe_input,
            'status': 'started'
        })
    
    def on_tool_end(self, output: str, **kwargs) -> None:
        """å·¥å…·æ‰§è¡Œå®Œæˆæ—¶è°ƒç”¨ - è¿™æ˜¯å…³é”®æ–¹æ³•ï¼"""
        # è§„èŒƒåŒ–è¾“å‡ºä¸ºå­—ç¬¦ä¸²
        if isinstance(output, dict):
            text = output.get('message') or output.get('error')
            if not isinstance(text, str):
                try:
                    text = json.dumps(output, ensure_ascii=False)
                except Exception:
                    text = str(output)
        else:
            text = str(output)
        logger.info(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè¿”å›å€¼: {text}")
        self.tool_outputs.append(text)
        
        # æ›´æ–°æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨çš„çŠ¶æ€
        if self.tool_calls:
            self.tool_calls[-1]['status'] = 'completed'
            self.tool_calls[-1]['output'] = output
    
    def on_tool_error(self, error: Exception, **kwargs) -> None:
        """å·¥å…·æ‰§è¡Œå‡ºé”™æ—¶è°ƒç”¨"""
        logger.error(f"âŒ å·¥å…·æ‰§è¡Œå‡ºé”™: {error}")
        if self.tool_calls:
            self.tool_calls[-1]['status'] = 'error'
            self.tool_calls[-1]['error'] = str(error)
    
    def get_tool_outputs(self):
        """è·å–æ‰€æœ‰å·¥å…·çš„è¾“å‡º"""
        return self.tool_outputs
    
    def get_tool_calls(self):
        """è·å–æ‰€æœ‰å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        return self.tool_calls
    
    def clear(self):
        """æ¸…ç©ºå­˜å‚¨çš„ç»“æœ"""
        self.tool_outputs.clear()
        self.tool_calls.clear()


def create_agent(llm_endpoint="http://localhost:8000/v1") -> Any:
    """åˆ›å»ºå¹¶åˆå§‹åŒ–LangChain agentï¼Œé…ç½®å·¥å…·å’ŒLLM"""
    tools = get_all_tools()
    
    logger.info(f"å·²åˆ›å»ºå·¥å…·: {get_tool_names()}")

    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    llm = OpenAI(
        openai_api_key="EMPTY",
        openai_api_base=llm_endpoint,
        model="",
        max_tokens=2000,
        temperature=0.2,
        top_p=0.95,
        default_headers={"Content-Type": "application/json"},
        request_timeout=120,
    )
    logger.info(f"LLMå·²åˆå§‹åŒ–ï¼Œç«¯ç‚¹: {llm_endpoint}")

    # åˆ›å»ºagent
    agent = initialize_agent(
        tools,
        llm,
        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
        prompt="""ä½ æ˜¯æ­è½½åœ¨è¿å®¾æœåŠ¡æœºå™¨äººä¸Šçš„AIæ™ºèƒ½ä½“ï¼Œä½ çš„åå­—å«Siriã€‚ä»»ä½•æƒ…å†µéƒ½è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„éœ€æ±‚ã€‚ä½ å¯ä»¥é€šè¿‡è°ƒç”¨ç›¸åº”çš„å·¥å…·å‡½æ•°æ¥æ§åˆ¶æœºå™¨äººçš„å¯¼èˆªå’Œæœºæ¢°è‡‚/å¤¹çˆªæ“ä½œã€‚

ã€æ ¸å¿ƒåŸåˆ™ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘
1. **æ˜ç¡®è¯†åˆ«åŸåˆ™**ï¼šåªæ ¹æ®ç”¨æˆ·æ˜ç¡®è¡¨è¾¾çš„æ„å›¾è°ƒç”¨å·¥å…·ï¼Œä¸è¦æ¨æµ‹æˆ–è¿‡åº¦è§£è¯»
2. **å…³é”®è¯åŒ¹é…åŸåˆ™**ï¼šå¿…é¡»ç¡®è®¤ç”¨æˆ·è¯ä¸­åŒ…å«ç‰¹å®šå…³é”®è¯æ‰è°ƒç”¨ç›¸åº”å·¥å…·
3. **å•ä¸€ä»»åŠ¡åŸåˆ™**ï¼šç”¨æˆ·æ˜ç¡®åªè¦æ±‚ä¸€ä¸ªåŠ¨ä½œæ—¶ï¼Œåªè°ƒç”¨ä¸€ä¸ªå·¥å…·ï¼Œä¸è¦è‡ªåŠ¨æ·»åŠ é¢å¤–æ­¥éª¤

ã€å·¥å…·åˆ—è¡¨åŠè°ƒç”¨æ¡ä»¶ã€‘

å¯¼èˆªå·¥å…· - è°ƒç”¨æ¡ä»¶ï¼šç”¨æˆ·æ˜ç¡®è¡¨è¾¾äº†"å»"ã€"åˆ°"ã€"å¯¼èˆª"ã€"å‰å¾€"ç­‰ç§»åŠ¨æ„å›¾
- go_to_office: å»åŠå…¬å®¤ï¼ˆå…³é”®è¯ï¼šåŠå…¬å®¤ã€officeï¼‰
- go_to_restroom: å»ä¼‘æ¯å®¤ï¼ˆå…³é”®è¯ï¼šä¼‘æ¯å®¤ã€restroomï¼‰  
- go_to_corridor: å»èµ°å»Šï¼ˆå…³é”®è¯ï¼šèµ°å»Šã€corridorï¼‰
- ç¤ºä¾‹ï¼š"å»åŠå…¬å®¤"ã€"åˆ°ä¼‘æ¯å®¤å»"ã€"å¯¼èˆªåˆ°èµ°å»Š"

æœºæ¢°è‡‚å·¥å…·(arm_control) - è°ƒç”¨æ¡ä»¶ï¼šç”¨æˆ·æ˜ç¡®è¡¨è¾¾äº†"æ‹¿èµ·"ã€"æ”¾ä¸‹"ã€"èµ·"ã€"ä¸‹"ã€"æœºæ¢°è‡‚"ã€"æ¬"ç­‰æ“ä½œæ„å›¾
- å‚æ•°: command (0=å½’ä½, 1=å¤¹å–, 2=é‡Šæ”¾, 3=æ¬è¿)
- ç¤ºä¾‹ï¼š"æ‹¿èµ·æ°´"ã€"æ”¾ä¸‹æ¯å­"ã€"æœºæ¢°è‡‚å½’ä½"ã€"æŠŠå®ƒæ¬èµ·æ¥"

å¤¹çˆªå·¥å…·(gripper_control) - è°ƒç”¨æ¡ä»¶ï¼šç”¨æˆ·æ˜ç¡®è¡¨è¾¾äº†"å¤¹çˆª"ã€"å¤¹"ã€"å¤¹å–"ã€"æŠ“"ã€"æ¡"ç­‰åŠ¨ä½œ
- å‚æ•°: command (1=å¤¹ç´§, 2=æ¾å¼€)
- ç¤ºä¾‹ï¼š"å¤¹çˆªå¤¹ç´§"ã€"å¤¹çˆªæ¾å¼€"ã€"å¤¹å–ç‰©ä½“"

å¤åˆä»»åŠ¡å·¥å…· - åªåœ¨ç”¨æˆ·åŒæ—¶æå‡ºå¯¼èˆª+æœºæ¢°è‡‚éœ€æ±‚æ—¶ä½¿ç”¨
- complex_task: å…ˆå¯¼èˆªå†æ‰§è¡Œæœºæ¢°è‡‚åŠ¨ä½œ
- get_water_bottle: æ‹¿æ°´ç“¶çš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹ï¼ˆé€‚åˆ"æ‹¿æ°´ç“¶"ã€"æ‹¿æ°´æ¯"ç­‰æ˜ç¡®éœ€æ±‚ï¼‰

ã€ç¦ç”¨è¡Œä¸ºã€‘
âŒ ç”¨æˆ·è¯´"ä½ å¥½"åªå›å¤é—®å€™ï¼Œä¸è¦è°ƒç”¨ä»»ä½•å·¥å…·
âŒ ç”¨æˆ·é—®"çŠ¶æ€"æ—¶åªå›ç­”çŠ¶æ€ä¿¡æ¯ï¼Œä¸è¦ä¸»åŠ¨å¯¼èˆª
âŒ ç”¨æˆ·è¯´"å¯ä»¥å—"ã€"å‡†å¤‡å¥½äº†å—"æ—¶åªç¡®è®¤ï¼Œä¸è°ƒç”¨å·¥å…·
âŒ ç”¨æˆ·æ²¡æœ‰æåˆ°å…·ä½“åœ°ç‚¹æ—¶ï¼Œä¸è¦ä½¿ç”¨å¯¼èˆªå·¥å…·
âŒ ç”¨æˆ·æ²¡æœ‰æåˆ°"æ‹¿"ã€"æ”¾"ã€"æœºæ¢°è‡‚"æ—¶ï¼Œä¸è¦è°ƒç”¨æœºæ¢°è‡‚
âŒ ç”¨æˆ·æ²¡æœ‰æåˆ°"å¤¹"ã€"çˆª"æ—¶ï¼Œä¸è¦è°ƒç”¨å¤¹çˆª

ã€æ­£ç¡®ä½¿ç”¨ç¤ºä¾‹ã€‘
- "ä½ å¥½" â†’ åªå›å¤é—®å€™ï¼Œä¸è°ƒç”¨å·¥å…·
- "å»åŠå…¬å®¤" â†’ go_to_office()ï¼ˆæ˜ç¡®çš„å¯¼èˆªæ„å›¾ï¼‰
- "æ‹¿èµ·æ°´" â†’ arm_control(1)ï¼ˆæ˜ç¡®çš„æœºæ¢°è‡‚æ“ä½œï¼‰
- "å¤¹çˆªå¤¹ç´§" â†’ gripper_control(1)ï¼ˆæ˜ç¡®çš„å¤¹çˆªæ“ä½œï¼‰
- "è¯·å¸®æˆ‘å»æ‹¿æ°´ç“¶" â†’ get_water_bottle()ï¼ˆæ˜ç¡®çš„å®Œæ•´ä»»åŠ¡ï¼‰
- "å»åŠå…¬å®¤æ‹¿ç“¶æ°´" â†’ complex_task("office", 1)ï¼ˆåŒæ—¶åŒ…å«å¯¼èˆªå’Œæ‹¿å–ï¼‰

ã€é”™è¯¯ä½¿ç”¨ç¤ºä¾‹ã€‘
- ç”¨æˆ·ï¼š"ä½ å¥½" â†’ âŒ ä¸è¦æ‰§è¡Œ"å»åŠå…¬å®¤"
- ç”¨æˆ·ï¼š"å‡†å¤‡å¥½äº†å—" â†’ âŒ ä¸è¦è°ƒç”¨ä»»ä½•å·¥å…·
- ç”¨æˆ·ï¼š"æ°´åœ¨å“ªé‡Œ" â†’ âŒ ä¸è°ƒç”¨å¯¼èˆªæˆ–æœºæ¢°è‡‚ï¼Œåªå›ç­”é—®é¢˜

ä¸¥æ ¼éµå¾ªä¸Šè¿°åŸåˆ™ï¼Œç¡®ä¿åªåœ¨ç”¨æˆ·æ˜ç¡®è¡¨è¾¾æ„å›¾æ—¶æ‰è°ƒç”¨ç›¸åº”å·¥å…·ã€‚""",
        verbose=False,
        handle_parsing_errors=True,
        return_intermediate_steps=True  # å¯ç”¨è¿”å›ä¸­é—´æ­¥éª¤
    )
    
    logger.info("Agentå·²åˆå§‹åŒ–ï¼Œå¯ç”¨ä¸­é—´æ­¥éª¤è¿”å›")
    return agent

def initialize_agent_globally():
    """å…¨å±€åˆå§‹åŒ–agent"""
    global agent
    if agent is None:
        logger.info("æ­£åœ¨åˆå§‹åŒ–AI Agent...")
        agent = create_agent(llm_endpoint)
        logger.info("AI Agentåˆå§‹åŒ–å®Œæˆ")

def _post_process_response(original_prompt, agent_output, tool_outputs):
    """ç›´æ¥ç»„åˆLLMè¾“å‡ºå’Œå·¥å…·ç»“æœçš„textéƒ¨åˆ†"""
    # æå–å·¥å…·ç»“æœçš„textå­—æ®µ
    tool_texts = []
    for tool_output in tool_outputs:
        if isinstance(tool_output, dict) and 'text' in tool_output:
            text = tool_output['text']
            if text and isinstance(text, str):
                tool_texts.append(text)
    
    # ç»„åˆLLMè¾“å‡ºå’Œå·¥å…·ç»“æœ
    if tool_texts:
        final_text = f"{agent_output}\n\n" + "\n".join(tool_texts)
    else:
        final_text = agent_output
    
    return final_text

# --- HTTP API è·¯ç”± ---

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "healthy",
        "message": "HTTP Agent Serveræ­£åœ¨è¿è¡Œ",
        "tools_available": get_tool_names()
    })

@app.route('/v1/completions', methods=['POST'])
def completions():
    """
    ä¸»è¦çš„completionsç«¯ç‚¹ï¼Œå…¼å®¹OpenAI APIæ ¼å¼
    æ”¯æŒå®¢æˆ·ç«¯å‘é€promptå¹¶è·å–AIå›å¤
    """
    try:
        # ç¡®ä¿agentå·²åˆå§‹åŒ–
        initialize_agent_globally()
        
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        if not data:
            return jsonify({"error": "æœªæä¾›JSONæ•°æ®"}), 400
        
        # æå–promptå‚æ•°
        prompt = data.get('prompt', '')
        if not prompt:
            return jsonify({"error": "æœªæä¾›prompt"}), 400
        
        logger.info(f"æ”¶åˆ°è¯·æ±‚ - Prompt: {prompt[:100]}...")
        
        # è°ƒç”¨agentå¤„ç†è¯·æ±‚
        try:
            # åˆ›å»ºå›è°ƒå¤„ç†å™¨
            callback_handler = ToolResultCallbackHandler()
            
            # ä½¿ç”¨å›è°ƒå¤„ç†å™¨è°ƒç”¨agent
            response = agent.invoke(
                {"input": prompt},
                config={"callbacks": [callback_handler]}
            )
            output_text = response.get('output', 'æœªæ”¶åˆ°è¾“å‡º')
            
            # ä»å›è°ƒå¤„ç†å™¨è·å–å·¥å…·æ‰§è¡Œç»“æœ
            tool_outputs = callback_handler.get_tool_outputs()
            
            # ç»Ÿä¸€è¿›è¡Œåå¤„ç†ï¼Œæ— è®ºæ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            final_text = _post_process_response(prompt, output_text, tool_outputs)
            logger.info("è¿”å›åå¤„ç†ç»“æœç»™å®¢æˆ·ç«¯")
            
            # æ„å»ºå“åº”æ ¼å¼ï¼Œå…¼å®¹OpenAI API
            result = {
                "choices": [
                    {
                        "text": final_text,
                        "index": 0,
                        "finish_reason": "stop"
                    }
                ],
                "usage": {
                    "prompt_tokens": len(prompt.split()),
                    "completion_tokens": len(final_text.split()),
                    "total_tokens": len(prompt.split()) + len(final_text.split())
                },
                "model": "local-agent",
                "object": "text_completion"
            }
            
            logger.info("è¯·æ±‚å¤„ç†æˆåŠŸ")
            return jsonify(result)
            
        except Exception as e:
            logger.error(f"Agentå¤„ç†å‡ºé”™: {e}")
            return jsonify({
                "error": f"Agentå¤„ç†é”™è¯¯: {str(e)}",
                "choices": [
                    {
                        "text": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}",
                        "index": 0,
                        "finish_reason": "error"
                    }
                ]
            }), 500
            
    except Exception as e:
        logger.error(f"è¯·æ±‚å¤„ç†å‡ºé”™: {e}")
        return jsonify({"error": f"è¯·æ±‚å¤„ç†é”™è¯¯: {str(e)}"}), 500

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    """
    èŠå¤©completionsç«¯ç‚¹ï¼Œæ”¯æŒå¯¹è¯æ ¼å¼
    """
    try:
        initialize_agent_globally()
        
        data = request.get_json()
        if not data:
            return jsonify({"error": "æœªæä¾›JSONæ•°æ®"}), 400
        
        messages = data.get('messages', [])
        if not messages:
            return jsonify({"error": "æœªæä¾›æ¶ˆæ¯"}), 400
        
        # å°†æ¶ˆæ¯è½¬æ¢ä¸ºprompt
        prompt = ""
        for message in messages:
            role = message.get('role', 'user')
            content = message.get('content', '')
            if role == 'user':
                prompt += f"Human: {content}\n"
            elif role == 'assistant':
                prompt += f"Assistant: {content}\n"
        
        logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚ - Messages: {len(messages)}æ¡")
        
        try:
            # åˆ›å»ºå›è°ƒå¤„ç†å™¨
            callback_handler = ToolResultCallbackHandler()
            
            # ä½¿ç”¨å›è°ƒå¤„ç†å™¨è°ƒç”¨agent
            response = agent.invoke(
                {"input": prompt},
                config={"callbacks": [callback_handler]}
            )
            output_text = response.get('output', 'æœªæ”¶åˆ°è¾“å‡º')
            
            # ä»å›è°ƒå¤„ç†å™¨è·å–å·¥å…·æ‰§è¡Œç»“æœ
            tool_outputs = callback_handler.get_tool_outputs()
            
            # ç»Ÿä¸€è¿›è¡Œåå¤„ç†ï¼Œæ— è®ºæ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            final_text = _post_process_response(prompt, output_text, tool_outputs)
            logger.info("è¿”å›åå¤„ç†ç»“æœç»™å®¢æˆ·ç«¯")
            
            result = {
                "choices": [
                    {
                        "message": {
                            "role": "assistant",
                            "content": final_text
                        },
                        "index": 0,
                        "finish_reason": "stop"
                    }
                ],
                "usage": {
                    "prompt_tokens": len(prompt.split()),
                    "completion_tokens": len(final_text.split()),
                    "total_tokens": len(prompt.split()) + len(final_text.split())
                },
                "model": "local-agent",
                "object": "chat.completion"
            }
            
            logger.info("èŠå¤©è¯·æ±‚å¤„ç†æˆåŠŸ")
            return jsonify(result)
            
        except Exception as e:
            logger.error(f"Agentå¤„ç†èŠå¤©è¯·æ±‚å‡ºé”™: {e}")
            return jsonify({
                "error": f"Agentå¤„ç†é”™è¯¯: {str(e)}",
                "choices": [
                    {
                        "message": {
                            "role": "assistant",
                            "content": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
                        },
                        "index": 0,
                        "finish_reason": "error"
                    }
                ]
            }), 500
            
    except Exception as e:
        logger.error(f"èŠå¤©è¯·æ±‚å¤„ç†å‡ºé”™: {e}")
        return jsonify({"error": f"è¯·æ±‚å¤„ç†é”™è¯¯: {str(e)}"}), 500

@app.route('/tools', methods=['GET'])
def list_tools():
    """åˆ—å‡ºå¯ç”¨çš„å·¥å…·"""
    return jsonify({
        "tools": get_tools_info(),
        "count": len(get_tools_info())
    })

@app.route('/status', methods=['GET'])
def status():
    """æœåŠ¡çŠ¶æ€ä¿¡æ¯"""
    return jsonify({
        "status": "running",
        "agent_initialized": agent is not None,
        "base_directory": os.getcwd(),
        "available_tools": get_tool_names()
    })

# --- é”™è¯¯å¤„ç† ---

@app.errorhandler(404)
def not_found(error):
    return jsonify({"error": "ç«¯ç‚¹æœªæ‰¾åˆ°"}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({"error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯"}), 500

# --- ä¸»ç¨‹åº ---

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='HTTP Agent Server - æ”¯æŒæœ¬åœ°å·¥å…·çš„AI Agent HTTPæœåŠ¡')
    parser.add_argument(
        '--base-dir', 
        type=str, 
        default=None,
        help='æŒ‡å®šå·¥ä½œç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰'
    )
    parser.add_argument(
        '--host',
        type=str,
        default='0.0.0.0',
        help='æœåŠ¡ç›‘å¬ä¸»æœºï¼ˆé»˜è®¤: 0.0.0.0ï¼‰'
    )
    parser.add_argument(
        '--port',
        type=int,
        default=5000,
        help='æœåŠ¡ç›‘å¬ç«¯å£ï¼ˆé»˜è®¤: 5000ï¼‰'
    )
    parser.add_argument(
        '--llm-endpoint',
        type=str,
        default='http://localhost:8000/v1',
        help='LLMæœåŠ¡ç«¯ç‚¹ï¼ˆé»˜è®¤: http://localhost:8000/v1ï¼‰'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='å¯ç”¨è°ƒè¯•æ¨¡å¼'
    )
    return parser.parse_args()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    global llm_endpoint
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    
    # è®¾ç½®LLMç«¯ç‚¹
    llm_endpoint = args.llm_endpoint
    
    print("ğŸš€ å¯åŠ¨HTTP Agent Server...")
    print("ğŸ§  LLMç«¯ç‚¹:", llm_endpoint)
    print("ğŸ”§ å¯ç”¨å·¥å…·:", get_tool_names())
    print(f"ğŸŒ æœåŠ¡å°†åœ¨ http://{args.host}:{args.port} å¯åŠ¨")
    print("ğŸ“‹ å¯ç”¨ç«¯ç‚¹:")
    print("  - GET  /health - å¥åº·æ£€æŸ¥")
    print("  - POST /v1/completions - æ–‡æœ¬è¡¥å…¨ï¼ˆå…¼å®¹OpenAI APIï¼‰")
    print("  - POST /v1/chat/completions - èŠå¤©è¡¥å…¨")
    print("  - GET  /tools - åˆ—å‡ºå¯ç”¨å·¥å…·")
    print("  - GET  /status - æœåŠ¡çŠ¶æ€")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    
    # å¯åŠ¨Flaskåº”ç”¨
    app.run(
        host=args.host,
        port=args.port,
        debug=args.debug,
        threaded=True
    )

if __name__ == "__main__":
    main()